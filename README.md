# Not all reviews are created equal?

This project contains exploratory scripts for sentiment analysis on Amazon Review Dataset 2023.

> **Does the sentiment expressed in a review causally affect its helpfulness, as measured by helpful votes?**

---

## Table of Contents

1. [Overview](#overview)
2. [Dataset](#dataset)
3. [Sentiment Analysis](#sentiment-analysis)
4. [Quick Start](#quick-start)
5. [File Layout](#file-layout)
6. [Dependencies](#dependencies)

---

## Overview

1. **Samples** an equal number of raw reviews per Amazon category from the [McAuley‑Lab/Amazon‑Reviews‑2023](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023) HuggingFace dataset.
2. **Cleans** the text (lower‑cases, trims, drops very short reviews, counts tokens).
3. **Scores sentiment** with two approaches

   * **VADER** (`nltk` lexicon)
   * **Distil BERT** (`distilbert/distilbert-base-uncased-finetuned-sst-2-english`)
   <!-- * An additional **Multilingual BERT** (`nlptown/bert-base-multilingual-uncased-sentiment`) [Only for testing purpose] -->

4. Writes each intermediate dataset to CSV so you can inspect / reuse any stage.
5. Casual Inference on several datasets

By changing two flags you can benchmark VADER vs BERT latency on your own machine.

---

## Dataset

The [McAuley‑Lab/Amazon‑Reviews‑2023](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023) is a large-scale Amazon Reviews dataset.
This dataset of product reviews covers
a wide variety of product categories and provides
insights into customer opinions and behaviors on
Amazon.
Below is an aggregated summary of the dataset:

- Total Number of Reviews - 571.4M
- Total Number of Users - 240.8M
- Average Review Length (tokens) - 52.7
- Total categories - 34 (33 named categories and an "Unknown" category)

Since the entire dataset is pretty large, we randomly sample it.
The `dataset.py` defines function to generate and clean dataset
of different sizes. 

### Generating a sample of the dataset 
From each category the script selects a random sample equal to that specified by the `--category-size` argument.
It defaults to `100000`

### Cleaning the Reviews
The cleaning process is surmised below:

- Keeps only string reviews  
- Lower‑cases & strips
- Drops reviews ≤ 5 words<br>
- Adds `review_length`(total words in review) & `token_count` (total tokens in review)


```shell
python main.py --category-size=100000
```

## Sentiment Analysis

After preprocessing each text review we run sentiment analysis on the model.
We generate a `"negative"`, `"neurtal"`, and `"positive"` label for each review.

We use three techniques to generate these labels

1. VADER - We use `nltk`'s implementation of VADER sentiment analysis as a baseline.
2. BERT - For more accurate results we use a BERT finetuned for sentiment analysis, specifically [distilbert/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english). We assume it is a good fit, since it was trained on movie reviews. 

Due to compute constraints we could only generate sentiment analysis of the following `category_size`
- 10000  
- 25000 
- 50000 
- 100000
- 1000000 (VADER only) 

`disagreement.py` script lets you see differences in the labels generated by the two models.

## Quick Start

```bash
# 1. Set up a fresh venv (optional)
python -m venv .venv
source .venv/bin/activate   # or .venv\Scripts\activate on Windows

# 2. Install deps
pip install -r requirements.txt
#   (transformers, datasets, nltk, pandas, tqdm, torch, etc.)

# 3. Run the pipeline with default (100000 reviews / category)
python main.py
```

## File Layout (default `batch_size = 100000`)

```bash
reviews-100000.csv                     # raw sample, all 34 categories
reviews-100000-cleaned.csv             # lowercase, >5 words, token counts
reviews-100000-analysis-vader.csv      # + VADER sentiment
reviews-100000-analysis-bert.csv       # + BERT sentiment
```

---

## Dependencies

```
pandas
datasets>=2.0
transformers>=4.34
torch          # CUDA build recommended for GPU
tqdm
nltk
```

```python
# one‑time download for VADER
import nltk; nltk.download("vader_lexicon")
```

---

### License

MIT — do whatever you want, but cite the *McAuley‑Lab/Amazon‑Reviews‑2023* dataset if you publish results.